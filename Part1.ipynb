{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gttEcYZych3h"
      },
      "source": [
        "**Installing Wandb**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAwmBI8bbJe3"
      },
      "outputs": [],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZSvuJzBc4zd"
      },
      "source": [
        "**Import statements**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xnSuJiIBcv1O"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "import wandb\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiZOfP0Yrygd"
      },
      "source": [
        "**Load dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DKylrRlrxG0"
      },
      "outputs": [],
      "source": [
        "(trainX, trainy), (testX, testy) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_28PzNuacUyW"
      },
      "source": [
        "# **Question 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "foCbEVjGa8tg",
        "outputId": "a1583f5a-9e6b-4530-c6f3-cb4355671cbf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.10"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230226_101336-xbxheni4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m006/Assignment%201/runs/xbxheni4' target=\"_blank\">divine-river-9</a></strong> to <a href='https://wandb.ai/cs22m006/Assignment%201' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m006/Assignment%201' target=\"_blank\">https://wandb.ai/cs22m006/Assignment%201</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m006/Assignment%201/runs/xbxheni4' target=\"_blank\">https://wandb.ai/cs22m006/Assignment%201/runs/xbxheni4</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "k = len(class_names)\n",
        "wandb.init(\n",
        "    project=\"Assignment 1\",\n",
        ")\n",
        "def plotImagesOfEachClass():\n",
        "  image_labels = []\n",
        "  images = []\n",
        "  for i in range(len(trainX)):\n",
        "    if len(image_labels) == len(class_names):\n",
        "      break\n",
        "    if class_names[trainy[i]] not in image_labels:\n",
        "      image_labels.append(class_names[trainy[i]])\n",
        "      images.append(trainX[i])\n",
        "\n",
        "  wandb.log({\"examples \": [wandb.Image(img, caption=caption) for img, caption in zip(images, image_labels)]})\n",
        "\n",
        "plotImagesOfEachClass()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rUN0fivd4Yg"
      },
      "source": [
        "# **Question 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVxycC5wmAo_",
        "outputId": "91574afc-aa6f-40d9-c4f2-b3a87410243e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a=np.random.rand(2)\n",
        "a.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4KVDIokWeG9o"
      },
      "outputs": [],
      "source": [
        "def initializeWeightAndBias(num_hidden_layers, neurons_in_each_layer, num_images, k, image_size):\n",
        "  W = []\n",
        "  bias = []\n",
        "  W.append(np.random.uniform(-0.72, 0.72, (neurons_in_each_layer, 784)))\n",
        "  bias.append((np.random.uniform(-0.72, 0.72, (neurons_in_each_layer,1))))\n",
        "  for i in range(num_hidden_layers-1):\n",
        "    W.append((np.random.uniform(-0.72, 0.72, (neurons_in_each_layer, neurons_in_each_layer))))\n",
        "    bias.append((np.random.uniform(-0.72, 0.72, (neurons_in_each_layer,1))))\n",
        "  W.append(np.random.uniform(-0.72, 0.72, (k, neurons_in_each_layer)))\n",
        "  bias.append(np.random.uniform(-0.72, 0.72, (k,1)))\n",
        "  return W, bias\n",
        "\n",
        "def flattenList(X):\n",
        "  return X.flatten()\n",
        "\n",
        "def sigmoid(X):\n",
        "  return 1.0/(1.+np.exp(-X))\n",
        "\n",
        "def softmax(a):\n",
        "  return np.exp(a)/np.sum(np.exp(a))\n",
        "\n",
        "def feedForward(W, bias, X, num_hidden_layers, neurons_in_each_layer):\n",
        "  preactivation = []\n",
        "  activation = []\n",
        "  activation.append(X.reshape(784,1))\n",
        "  preactivation.append(X.reshape(784,1))\n",
        "  for i in range(1, num_hidden_layers+1):\n",
        "    preactivation.append(np.add(bias[i-1], np.matmul(W[i-1], activation[(i-1)])))\n",
        "    activation.append(sigmoid(preactivation[i]))\n",
        "  preactivation.append(np.add(bias[-1], np.dot(W[-1], activation[-1])))\n",
        "  activation.append(softmax(preactivation[-1]))\n",
        "  return activation, preactivation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QVmdL1b84nT3"
      },
      "outputs": [],
      "source": [
        "def updateParam(W, gradientW, bias, gradientBias, L, eta):\n",
        "  for i in range(0, len(W)):\n",
        "    W[i] = W[i] - eta*gradientW[i]\n",
        "    bias[i] = bias[i] - eta*gradientBias[i]\n",
        "  return W, bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ErzZSng_dki"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qRCs-OZUPD3W"
      },
      "outputs": [],
      "source": [
        "def derivative_sigmoid(x):\n",
        "  return sigmoid(x)*(np.ones_like(x)-sigmoid(x))\n",
        "def der_softmax(x):\n",
        "  return softmax(x)*(np.ones_like(x)-softmax(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "meGdgBul6FQJ"
      },
      "outputs": [],
      "source": [
        "def backward_propogation(x, y, W, bias, activation, preactivation, num_hidden_layers, neurons_in_each_layer, k, num_images, batchSize):\n",
        "  L = num_hidden_layers+1\n",
        "  gradientActivation = []\n",
        "  gradientPreactivation = []\n",
        "  exp_y = np.zeros((k,1))\n",
        "  exp_y[y][0] = 1\n",
        "  gradientPreactivation.append(-(exp_y-activation[L]))\n",
        "  gradientWeight = []\n",
        "  gradientBias = []\n",
        "\n",
        "  for k in range(L, 0, -1):\n",
        "    gradientWeight.append(np.matmul(gradientPreactivation[-1], activation[k-1].T)/batchSize)\n",
        "    gradientBias.append(gradientPreactivation[-1]/batchSize)\n",
        "    if k==1:\n",
        "      break\n",
        "    gradientActivation.append(np.matmul(W[k-1].T, gradientPreactivation[-1]))\n",
        "    gradientPreactivation.append(np.multiply(gradientActivation[-1], derivative_sigmoid(preactivation[k-1])))\n",
        "  return gradientWeight[::-1], gradientBias[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lvgQ1EXUJgzX"
      },
      "outputs": [],
      "source": [
        "def one_hot(i):\n",
        "  y = np.zeros((10,1))\n",
        "  y[i] = 1\n",
        "  return y\n",
        "\n",
        "def cross_entropy(true_output, predicted_output):\n",
        "  return -1.0*np.sum(true_output*np.log(predicted_output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-T4dE82QSVGS"
      },
      "outputs": [],
      "source": [
        "def stochastic_gradient_descent(num_hidden_layers, neurons_in_each_layer, num_images, image_size, trainX, trainY, epochs, eta):\n",
        "  W, bias = initializeWeightAndBias(num_hidden_layers, neurons_in_each_layer, num_images, k, image_size)\n",
        "  batchSize = 32\n",
        "  y_pred = []\n",
        "  print(epochs)\n",
        "  for iterationNumber in range(epochs):\n",
        "    gradientW = []\n",
        "    gradientBias = []\n",
        "    \n",
        "    correctPrediction = 0\n",
        "    print(iterationNumber)\n",
        "    loss=0\n",
        "    count=0\n",
        "    for i in range(num_images):\n",
        "      activation, preactivation = feedForward(W, bias, trainX[i], num_hidden_layers, neurons_in_each_layer)\n",
        "      loss += cross_entropy(one_hot(trainy[i]), activation[num_hidden_layers+1])\n",
        "      gradientW, gradientBias = backward_propogation(trainX[i], trainY[i], W, bias, activation, preactivation, num_hidden_layers, neurons_in_each_layer, k, num_images, batchSize)\n",
        "      if(count == 0):\n",
        "        currGradientW, currGradientBias = [], []\n",
        "        currGradientW = gradientW\n",
        "        currGradientBias = gradientBias\n",
        "      else:\n",
        "        for idx in range(0, len(gradientW)):\n",
        "          currGradientW[idx] += gradientW[idx] \n",
        "          currGradientBias[idx] += gradientBias[idx] \n",
        "      count += 1\n",
        "      if(iterationNumber==epochs-1):\n",
        "        y_pred.append(np.argmax(activation[num_hidden_layers+1]))\n",
        "      if count == batchSize:\n",
        "        count = 0\n",
        "        W, bias = updateParam(W, currGradientW, bias, currGradientBias, num_hidden_layers+1, eta)\n",
        "    print(loss/num_images)\n",
        "  return y_pred, W, bias\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mn1arCMJTH8C"
      },
      "outputs": [],
      "source": [
        "(trainX, trainy), (testX, testy) = fashion_mnist.load_data()\n",
        "num_hidden_layers = 3\n",
        "neurons_in_each_layer = 128\n",
        "num_images = len(trainX)\n",
        "k=10\n",
        "trainX.reshape(trainX.shape[0], trainX.shape[1]*trainX.shape[2])\n",
        "trainX = trainX/255.0\n",
        "testX = testX/255.0\n",
        "a, W, bias=stochastic_gradient_descent(num_hidden_layers, neurons_in_each_layer, num_images, 28*28, trainX, trainy, 6, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXqPcIYQNxvI",
        "outputId": "198d0a80-e017-4fad-89b9-f7c521ecd2a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on train data 86.32\n"
          ]
        }
      ],
      "source": [
        "cnt=0\n",
        "for i in range(len(a)):\n",
        "  if(a[i]==trainy[i]):\n",
        "    cnt+=1\n",
        "print(\"Accuracy on train data\", 100*cnt/len(a))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb6eMz2QXbIF",
        "outputId": "6673eaf6-d869-4778-825f-04255c893c2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test data 84.79\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "for i in range(len(testX)):\n",
        "  activation, preactivation = feedForward(W, bias, testX[i], num_hidden_layers, neurons_in_each_layer)\n",
        "  y_pred = np.argmax(activation[num_hidden_layers+1])\n",
        "  if(y_pred == testy[i]):\n",
        "    count+=1\n",
        "print(\"Accuracy on test data\", (100.0*count)/len(testy))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "4f76be80567250ef020264f67a4ffc851146841a04270231317fab593439cf08"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
