{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Installing Wandb**"
      ],
      "metadata": {
        "id": "gttEcYZych3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "dAwmBI8bbJe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import statements**"
      ],
      "metadata": {
        "id": "gZSvuJzBc4zd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "import wandb\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "xnSuJiIBcv1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1**"
      ],
      "metadata": {
        "id": "_28PzNuacUyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(trainX, trainy), (testX, testy) = fashion_mnist.load_data()\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "k = len(class_names)\n",
        "wandb.init(\n",
        "    project=\"Assignment 1\",\n",
        ")\n",
        "def plotImagesOfEachClass():\n",
        "  image_labels = []\n",
        "  images = []\n",
        "  for i in range(len(trainX)):\n",
        "    if len(image_labels) == len(class_names):\n",
        "      break\n",
        "    if class_names[trainy[i]] not in image_labels:\n",
        "      image_labels.append(class_names[trainy[i]])\n",
        "      images.append(trainX[i])\n",
        "\n",
        "  wandb.log({\"examples \": [wandb.Image(img, caption=caption) for img, caption in zip(images, image_labels)]})\n",
        "\n",
        "plotImagesOfEachClass()"
      ],
      "metadata": {
        "id": "foCbEVjGa8tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 2**"
      ],
      "metadata": {
        "id": "7rUN0fivd4Yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initializeWeightAndBias(num_hidden_layers, neurons_in_each_layer, num_images, k):\n",
        "  W = {}\n",
        "  bias = {}\n",
        "  W[\"1\"] = (np.random.randn(neurons_in_each_layer, 784))\n",
        "  bias[\"1\"] = (np.random.randn(neurons_in_each_layer))\n",
        "  for i in range(num_hidden_layers-1):\n",
        "    W[str(i+2)] = (np.random.randn(neurons_in_each_layer, neurons_in_each_layer))\n",
        "    bias[str(i+2)] = (np.random.randn(neurons_in_each_layer))\n",
        "  W[str(num_hidden_layers+1)] = (np.random.randn(k, neurons_in_each_layer))\n",
        "  bias[str(num_hidden_layers+1)] = (np.random.randn(k))\n",
        "  return W, bias\n",
        "\n",
        "def flattenList(X):\n",
        "  return X.flatten()\n",
        "\n",
        "def sigmoid(X):\n",
        "  return 1.0/(1+np.exp(-X))\n",
        "\n",
        "def softmax(a):\n",
        "  return np.exp(a) / np.sum(np.exp(a))\n",
        "\n",
        "def feedForward(W, bias, X, num_hidden_layers, neurons_in_each_layer):\n",
        "  preactivation = {}\n",
        "  activation = {}\n",
        "  h0 = flattenList(X)\n",
        "  activation[\"h0\"] = h0\n",
        "  for i in range(1, num_hidden_layers+1):\n",
        "    # print(i)\n",
        "    # print(bias[str(i)].shape)\n",
        "    # print(W[str(i)].shape)\n",
        "    # print(activation[\"h\"+str(i-1)].shape)\n",
        "    ai = bias[str(i)] + np.matmul(W[str(i)], activation[\"h\"+str(i-1)])\n",
        "    preactivation[\"a\"+str(i)] = ai\n",
        "    hi = sigmoid(ai)\n",
        "    activation[\"h\"+str(i)] = hi\n",
        "  preactivation[\"a\"+str(num_hidden_layers+1)] = bias[str(num_hidden_layers+1)] + np.matmul(W[str(num_hidden_layers+1)], activation[\"h\"+str(num_hidden_layers)])\n",
        "  # print(preactivation[\"a\"+str(num_hidden_layers+1)])\n",
        "  activation[\"h\"+str(num_hidden_layers+1)] = softmax(preactivation[\"a\"+str(num_hidden_layers+1)])\n",
        "  # print(activation)\n",
        "  return activation[\"h\"+str(num_hidden_layers+1)]\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4KVDIokWeG9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_hidden_layers = 4\n",
        "neurons_in_each_layer = 32\n",
        "num_images = len(trainX)\n",
        "W, bias = initializeWeightAndBias(num_hidden_layers, neurons_in_each_layer, num_images, k)\n",
        "probabilityDistribution = []\n",
        "for i in range(num_images):\n",
        "  probabilityDistribution.append(feedForward(W, bias, trainX[i], num_hidden_layers, neurons_in_each_layer))\n",
        "  print(np.argmax(probabilityDistribution[i]))"
      ],
      "metadata": {
        "id": "StWYvf_bHxlw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}